"""
åˆ›å»ºä¸ä¾èµ–è‡ªå®šä¹‰å‡½æ•°çš„ç®€åŒ–æ¨¡å‹
"""

import numpy as np
import joblib
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_simple_ad_model():
    """åˆ›å»ºç®€åŒ–çš„ADæ£€æµ‹æ¨¡å‹"""
    logger.info("åˆ›å»ºç®€åŒ–ADæ£€æµ‹æ¨¡å‹...")

    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    n_samples = 1000
    n_features = 286

    # åˆ›å»ºç‰¹å¾æ•°æ®
    np.random.seed(42)
    X = np.random.normal(0, 1, (n_samples, n_features))

    # åˆ›å»ºæ ‡ç­¾ - åŸºäºç‰¹å¾çš„ç®€å•é€»è¾‘
    # è®©å‰50ä¸ªç‰¹å¾å¯¹ADæœ‰å½±å“
    ad_weights = np.zeros(n_features)
    ad_weights[:50] = np.random.normal(0, 0.5, 50)

    # è®¡ç®—ADæ¦‚ç‡
    linear_combination = X @ ad_weights
    ad_prob = 1 / (1 + np.exp(-linear_combination))
    y = (ad_prob > 0.5).astype(int)

    # è°ƒæ•´ç±»åˆ«æ¯”ä¾‹
    ad_ratio = 0.3
    n_ad = int(n_samples * ad_ratio)
    ad_indices = np.where(y == 1)[0]
    non_ad_indices = np.where(y == 0)[0]

    if len(ad_indices) > n_ad:
        # éšæœºé€‰æ‹©éƒ¨åˆ†ADæ ·æœ¬è½¬ä¸ºéAD
        to_convert = np.random.choice(ad_indices, len(ad_indices) - n_ad, replace=False)
        y[to_convert] = 0
    elif len(ad_indices) < n_ad:
        # éšæœºé€‰æ‹©éƒ¨åˆ†éADæ ·æœ¬è½¬ä¸ºAD
        to_convert = np.random.choice(non_ad_indices, n_ad - len(ad_indices), replace=False)
        y[to_convert] = 1

    logger.info(f"æ•°æ®åˆ†å¸ƒ - AD: {np.sum(y)}, æ­£å¸¸: {len(y) - np.sum(y)}")

    # åˆ›å»ºç®€å•çš„ç®¡é“æ¨¡å‹
    model = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', RandomForestClassifier(
            n_estimators=50,
            max_depth=5,
            random_state=42,
            class_weight='balanced'
        ))
    ])

    # è®­ç»ƒæ¨¡å‹
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    model.fit(X_train, y_train)

    # è¯„ä¼°æ¨¡å‹
    train_score = model.score(X_train, y_train)
    test_score = model.score(X_test, y_test)

    logger.info(f"è®­ç»ƒå‡†ç¡®ç‡: {train_score:.4f}")
    logger.info(f"æµ‹è¯•å‡†ç¡®ç‡: {test_score:.4f}")

    return model


def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹åˆ›å»ºç®€åŒ–æ¨¡å‹...")

    try:
        # åˆ›å»ºæ¨¡å‹
        model = create_simple_ad_model()

        # ä¿å­˜æ¨¡å‹
        model_filename = 'ad_model_simple.pkl'
        joblib.dump(model, model_filename)

        logger.info(f"âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ: {model_filename}")

        # æµ‹è¯•æ¨¡å‹åŠ è½½
        loaded_model = joblib.load(model_filename)
        logger.info("âœ… æ¨¡å‹åŠ è½½æµ‹è¯•æˆåŠŸ")

        # æµ‹è¯•é¢„æµ‹
        test_sample = np.random.normal(0, 1, (1, 286))
        prediction = loaded_model.predict_proba(test_sample)
        logger.info(f"âœ… é¢„æµ‹æµ‹è¯•æˆåŠŸ - æ¦‚ç‡: {prediction[0]}")

        print(f"\nğŸ‰ ç®€åŒ–æ¨¡å‹åˆ›å»ºæˆåŠŸï¼")
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {model_filename}")
        print(f"ğŸ”§ ä¸‹ä¸€æ­¥: ä¿®æ”¹ new.api.py ä½¿ç”¨æ–°æ¨¡å‹æ–‡ä»¶")

    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()